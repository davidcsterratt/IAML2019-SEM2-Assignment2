{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory Applied Machine Learning (IAML) Assignment 2 - Semester 2, March 2020. \n",
    "\n",
    "\n",
    "#### Authors: Fazl Barez and David Sterratt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "**It is important that you follow the instructions below carefully for things to work properly.**\n",
    "\n",
    "1. You need to set up and activate your environment as you would do for your labs, i.e. by reading the instructions in the labs [README](https://github.com/davidcsterratt/iaml-labs) file.\n",
    "\n",
    "2. Read the instructions in this notebook carefully, especially where asked to name variables with a specific name. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers. In most cases we indicate the nature of answer we are expecting (code/text), and also provide the required code/markdown cell.\n",
    "\n",
    "3. The `.csv` files that you will be using are located in the `./datasets` directory that is included in the git repository with this file.\n",
    "\n",
    "1. <span style=\"color:red\">Keep your answers brief and concise. Most written questions can be answered in 2-3 lines.</span>\n",
    "\n",
    "1. Make sure to distinguish between **attributes** (columns of the data) and **features** (which typically refers only to the independent variables, i.e. excluding the target variables).\n",
    "\n",
    "1. Make sure to show **all** your code/working. \n",
    "\n",
    "1. Write readable code. While we do not expect you to follow [PEP8](https://www.python.org/dev/peps/pep-0008/) to the letter, the code should be adequately understandable, with plots/visualisations correctly labelled. **Do** use inline comments when doing something non-standard. When asked to present numerical values, make sure to represent real numbers in the appropriate precision to exemplify your answer.\n",
    "\n",
    "### SUBMISSION Mechanics\n",
    "\n",
    "This assignment will account for 25% of your final mark. We ask you\n",
    "to submit answers to all questions.\n",
    "\n",
    "**Submissions will be made on Learn, on a specific page that will be set up and announced before the deadline.** You can find details on how the submission on Learn works [here](https://blogs.ed.ac.uk/ilts/2019/09/27/assignment-hand-ins-for-learn-guidance-for-students/). You need only submit this file, filled in with your answers (please do not rename it). Please **save the file with cells run** such that any output has been already produced. We recommend that you make sure all cells run by selecting **Kernel->Restart & Run all** before you submit. Allow 20 minutes for this, as some of the cells take some time to run.\n",
    "\n",
    "The submission deadline for this assignment is **Monday 30/03/2019 at 16:00 UK time (BST)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS\n",
    "\n",
    "Execute the cell below to import all packages you will be using for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn 0.22.2 has helpful functions sklearn.metrics.roc_curve\n",
    "# and sklearn.metrics.precision_recall_curve\n",
    "!pip install scikit-learn==0.22.2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "np.random.seed(260393)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, GridSearchCV\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All packages imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 Exploratory Analysis\n",
    "## Polish Companies Bankruptcy (PCB) Dataset\n",
    "\n",
    "This question is based on the Polish Companies Bankruptcy (PCB) dataset. The task is to predict bankruptcy of Polish companies on the basis of a number of features. The data was collected from the [Emerging Markets Information Service (EMIS)](https://www.emis.com/), which is a database containing information on emerging markets around the world. The bankrupt companies were analysed over the period 2000-2012. The companies still operating were analysed from 2007 to 2013. This data is hosted at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data#).\n",
    "\n",
    "We have preprocessed the files contained at in the UCI Machine Learning Repository to create a full dataset. We have ensured that there is no missing data. We have then created training and testing data files by randomly selecting instances from the full dataset. The files are contained in the `./datasets` directory.\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "attr1 - net profit / total assets <br>\n",
    "attr2 - total liabilities / total assets <br>\n",
    "attr3 - working capital / total assets<br>\n",
    "attr4 - current assets / short-term liabilities<br>\n",
    "attr5 -[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365<br>\n",
    "attr6 - retained earnings / total assets<br>\n",
    "attr7 - EBIT / total assets<br>\n",
    "attr8 - book value of equity / total liabilities<br>\n",
    "attr9 - sales / total assets<br>\n",
    "attr10 - equity / total assets<br>\n",
    "attr11 - (gross profit + extraordinary items + financial expenses) / total assets<br>\n",
    "attr12 - gross profit / short-term liabilities<br>\n",
    "attr13 - (gross profit + depreciation) / sales<br>\n",
    "attr14 - (gross profit + interest) / total assets<br>\n",
    "attr15 - (total liabilities * 365) / (gross profit + depreciation)<br>\n",
    "attr16 - (gross profit + depreciation) / total liabilities<br>\n",
    "attr17 - total assets / total liabilities<br>\n",
    "attr18 - gross profit / total assets<br>\n",
    "attr19 - gross profit / sales<br>\n",
    "attr20 - (inventory * 365) / sales<br>\n",
    "attr21 - sales (n) / sales (n-1)<br>\n",
    "attr22 - profit on operating activities / total assets<br>\n",
    "attr23 - net profit / sales<br>\n",
    "attr24 - gross profit (in 3 years) / total assets<br>\n",
    "attr25 - (equity - share capital) / total assets<br>\n",
    "attr26 - (net profit + depreciation) / total liabilities<br>\n",
    "attr27 - profit on operating activities / financial expenses<br>\n",
    "attr28 - working capital / fixed assets<br>\n",
    "attr29 - logarithm of total assets<br>\n",
    "attr30 - (total liabilities - cash) / sales<br>\n",
    "attr31 - (gross profit + interest) / sales<br>\n",
    "attr32 - (current liabilities * 365) / cost of products sold<br>\n",
    "attr33 - operating expenses / short-term liabilities<br>\n",
    "attr34 - operating expenses / total liabilities<br>\n",
    "attr35 - profit on sales / total assets<br>\n",
    "attr36 - total sales / total assets<br>\n",
    "attr37 - (current assets - inventories) / long-term liabilities<br>\n",
    "attr38 - constant capital / total assets<br>\n",
    "attr39 - profit on sales / sales<br>\n",
    "attr40 - (current assets - inventory - receivables) / short-term liabilities<br>\n",
    "attr41 - total liabilities / ((profit on operating activities + depreciation) * (12/365))<br>\n",
    "attr42 - profit on operating activities / sales<br>\n",
    "attr43 - rotation receivables + inventory turnover in days<br>\n",
    "attr44 - (receivables * 365) / sales<br>\n",
    "attr45 - net profit / inventory<br>\n",
    "attr46 - (current assets - inventory) / short-term liabilities<br>\n",
    "attr47 - (inventory * 365) / cost of products sold<br>\n",
    "attr48 - EBITDA (profit on operating activities - depreciation) / total assets<br>\n",
    "attr49 - EBITDA (profit on operating activities - depreciation) / sales<br>\n",
    "attr50 - current assets / total liabilities<br>\n",
    "attr51 - short-term liabilities / total assets<br>\n",
    "attr52 - (short-term liabilities * 365) / cost of products sold)<br>\n",
    "attr53 - equity / fixed assets<br>\n",
    "attr54 - constant capital / fixed assets<br>\n",
    "attr55 - working capital<br>\n",
    "attr56 - (sales - cost of products sold) / sales<br>\n",
    "attr57 - (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)<br>\n",
    "attr58 - total costs /total sales<br>\n",
    "attr59 - long-term liabilities / equity<br>\n",
    "attr60 - sales / inventory<br>\n",
    "attr61 - sales / receivables<br>\n",
    "attr62 - (short-term liabilities *365) / sales<br>\n",
    "attr63 - sales / short-term liabilities<br>\n",
    "attr64 - sales / fixed assets<br>\n",
    "class - the response variable Y: 0 = did not bankrupt; 1 = bankrupt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 --- [10 marks] ==========\n",
    "\n",
    "1. [Code] Load the dataset `Bankruptcy_Train.csv` and `Bankruptcy_Test.csv` into two DataFrames named `pcb_train` and `pcb_test` respectively. Using pandas methods learned in the labs, extract some basic information about the training data.\n",
    "\n",
    "2. [Text] In a short paragraph, summarise the key features of the training data. Focus on the dimensionality and data ranges and report anything out of the ordinary.\n",
    "\n",
    "**Hint: Look at what we did in the labs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 --- [5 marks] ==========\n",
    "\n",
    "1. [Code] Extract the same information about the testing data as you have for the training data.\n",
    "2. [Text] How does the testing data compare with the training data (in terms of sizes and feature distributions)? What would be the implications of bigger or smaller testing sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 --- [14 marks] ==========\n",
    "1. [Text] Give a brief description of the classification learning task.\n",
    "\n",
    "2. [Code] Print and plot the number of positive and negative instances for the target class in the training *and* test data. Also give the number of positive instances as a fraction of the total number of instances. **Hint:** You may use the seaborn `countplot` function for the plot, and pandas `value_counts` for the numbers and fractions.\n",
    "\n",
    "3. [Text] Describe the output. Comment (2 or 3 sentences) on the implications of having imbalanced classes in classification.\n",
    "\n",
    "4. [Text] Familiarise yourself with the F1 score, which is related to the precision and recall we learned about in the video lectures. Define the F1 score. Why is it preferable to the accuracy in our problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 --- [15 marks] ==========\n",
    "\n",
    "1. [Text] What is the meaning of the attributes `Attr1`, `Attr2`, `Attr5`, `Attr15` and `Attr29`? Refer back to the data description, and comment on the nature of the attributes.\n",
    "\n",
    "2. [Code] Use the seaborn `pairplot` function to visualise the relationships between `Attr1`, `Attr2`, `Attr5`, `Attr15` and `Attr29` in the training data. Indicate the class of each datapoint with the hue. **Hint** Use `figsize=(10, 10)` to make the plot clear.\n",
    "\n",
    "3. [Text] What do you observe in the plots? Do the distributions of any attributes look different to the others? Can you explain why the distributions might look as they do, by referring back to the meanings of the attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 --- [12 marks] ==========\n",
    "\n",
    "We are now going to experiment with transforming the data using an inverse sinh (hyperbolic sin) function, which is called `np.arcsinh` in Python.\n",
    "\n",
    "1. [Code] First of all plot the inverse sinh function for the range of values -100 to 100. Remember to label the axes.\n",
    "2. [Text] Explain what effect this function will have on large and small values.\n",
    "3. [Code] We have supplied some code to demonstrate the effect of the transform on the training data. Run this code and then produce pairplots for the `pcb_train_trans` variable.\n",
    "4. [Text] Compare the pairplots with the ones in Question 1.4. What characteristics of the data is it now possible to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform code - run this\n",
    "X_train_trans = pcb_train.drop('class', axis=1)\n",
    "X_train_trans = np.arcsinh(X_train_trans)\n",
    "pcb_train_trans = pd.concat([X_train_trans, pd.DataFrame(pcb_train['class'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transformation\"></a>\n",
    "## Important Instruction: Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions 2, 3, 4 and 5, it is **crucial** that you use a transformed version of the PCB testing and training datasets. We will call them `pcb_trans_train` and `pcb_trans_test`. Run the cell below, and from now on always use the transformed data `pcb_trans_train` and `pcb_trans_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "def transform_pcb(pcb):\n",
    "    pcb_trans = pd.concat([pcb[pcb.columns[0:28]].transform(np.arcsinh),\n",
    "                           pcb[pcb.columns[28]],\n",
    "                           pcb[pcb.columns[29:64]].transform(np.arcsinh),\n",
    "                           pcb['class']],\n",
    "                          axis=1)\n",
    "    return(pcb_trans)\n",
    "\n",
    "pcb_trans_train = transform_pcb(pcb_train)\n",
    "pcb_trans_test  = transform_pcb(pcb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 Gaussian Naive Bayes classification \n",
    "\n",
    "Now we want to fit a Gaussian Naive Bayes (GNB) model to the dataset. You should first familiarise yourself with the [`GaussianNB`](http://scikit-learn.org/0.22/modules/generated/sklearn.naive_bayes.GaussianNB.html) class in `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 --- [8 marks] ==========\n",
    "\n",
    "Answer (in brief) the following two questions:\n",
    "1. [Text]  Naive Bayes assumes that features are conditionally independent given the label. What additional assumptions are made in *Gaussian* Naive Bayes about the type of the data and its distribution?\n",
    "\n",
    "2. [Text] Why can Gaussian Naive Bayes be applied to the dataset? Given the limited exploratory analysis you carried out, comment on how well the assumptions of GNB match the data. There is no need to look at all the features - just look at the features you were asked to plot in Question 1.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 --- [10 marks] ==========\n",
    "1. [Text] What is a reasonable baseline against which to compare the classification performance? **Hint:** What is the simplest \"classifier\" you can think of, which will give high accuracy with imbalanced classes.\n",
    "\n",
    "2. [Code] Estimate the baseline performance on the **training** data in terms of classification accuracy and the precision, recall and F1 measure.  Also report the confusion matrix and the normalised confusion matrix. **Hints**:\n",
    "    - For precision, recall and F1, look at the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) documentation\n",
    "    - Use the `plot_confusion_matrix` function defined in the labs.\n",
    "    - You may make use of the arguments to scikit-learn's `confusion_matrix` function to compute normalised confusion matrices.\n",
    "\n",
    "3. [Text] Comment on the results, including the difference between the accuracy and the F1  measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_2_3'></a>\n",
    "### ========== Question 2.3 --- [10 marks] ==========\n",
    "\n",
    "1. [Code] Fit a Gaussian Naive Bayes model to the dataset. **Remember to use the [transformed data](#transformation) `pcb_trans_train`.** **Hint:** Create an `GaussianNB` object and give it a memorable name, e.g. `gnb`. You will need to refer to it later. \n",
    "\n",
    "2. [Code] Report the classifier's accuracy, precision and recall and F1  on the **training** dataset.  Also report the confusion matrix and the normalised confusion matrix for the result.\n",
    "\n",
    "3. [Text] Interpret the values of the accuracy, F1, precision and recall. Comment on the performance of the model, comparing to the baseline. Is the accuracy a reasonable metric to use for this dataset? Interpret the numbers in the confusion matrix. Does it look like you would expect to find in a \"good\" classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 --- [8 marks] ==========\n",
    "\n",
    "Now we want to evaluate the generalisation of the classifier on new  (i.e. unseen) data. \n",
    "\n",
    "1. [Code] Apply the classifier you trained in Question [2.3](#question_2_3) to the **test** dataset, `pcb_trans_test`. Report the classifier's accuracy, precision and recall and F1. Also report the confusion matrix and the normalised confusion matrix.\n",
    "\n",
    "2. [Code] Also reevaluate the performance of the baseline classifier on the test data.\n",
    "\n",
    "3. [Text] In a short paragraph (3-4 sentences) compare and comment on the results with (a) the training data and (b) the baseline (on the test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 Decision Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.1 --- [16 marks] ==========\n",
    "\n",
    "1. [Code] Fit a Decision Tree classifier to the training data, using max entropy as the splitting criterion. Remember to give the classifier a unique name, e.g. `dt`.\n",
    "\n",
    "2. [Code] Report the classifier's accuracy, precision and recall and F1  on both the **training** and **testing** datasets `pcb_trans_train` and `pcb_trans_test`. Also report the confusion matrix and the plot the normalised confusion matrix for both datasets.\n",
    "\n",
    "3. [Text] Comment on the results, comparing with the baseline performance and the Gaussian Naive Bayes performance.\n",
    "\n",
    "4. [Code] Run the [`classification_report`](https://scikit-learn.org/stable/module/generate/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) function on the true and predicted labels.\n",
    "\n",
    "5. [Text] Explain the output of the function. To do this you will need to read the documentation for the scikit-learn `classification_report` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.2 --- [23 marks] ==========\n",
    "We are now going to set the hyper-parameters of the Decision Tree classifier so as to make it generalise better.\n",
    "\n",
    "1. [Text] Describe how the `max_depth` and `min_samples_leaf` hyperparameters affect the behaviour of the `DecisionTree` classifier.\n",
    "\n",
    "2. [Text] Look at the documentation of the scikit-learn `GridSearchCV` function and the page in the scikit-learn user guide on [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search). Explain briefly what the `GridSearchCV` function does, and the meaning of the `estimator`, `param_grid` and `scoring` arguments.\n",
    "\n",
    "3. [Code] Use `GridSearchCV` to explore the performance, measured using the F1 metric, of decision trees with a max entropy splitting criterion  and all possible combinations of `max_depth=[None, 2, 15, 25]` and `min_samples_leaf=[1, 5, 10, 20, 50]`.  **Hint:** Create a  `GridSearchCV` object called `dtgs`. Pass it a `DecisionTree` classifier  with the splitting criterion set to `entropy` and, for reproducibility, with the `random_state` set to 0.  The metric is specified by setting the `scoring` parameter of `GridSearchCV` to `f1`. Use the `fit` method with the training data to fit the decision trees. You can use the default value of the other parameters to `GridSearchCV`, but you may wish to set `verbose=1` to get messages about the progress - this function will take some time to run.\n",
    "\n",
    "4. [Code] Use the `score` method of the GridSearchCV object you've just created to report the F1 score on **all** the training data and the test set. Print the best set of parameters which are held in the `best_params_` field. \n",
    "\n",
    "5. [Text] Comment on the parameters chosen - are they different from the default parameters, i.e. those present in a `DecsionTree` classifier without parameters specified?\n",
    " \n",
    "6. [Code] Use the `predict` method to generate and plot the normalised confusion matrix and print the classification report as in Question 3.1.\n",
    "\n",
    "7. [Text] Comment on the results. Pay attention to comparing the metrics (F1 and confusion matrix) on the training data and the test data, and explain any differences with the results obtained in Question 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) # Your code goes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4.1 --- [23 marks] ==========\n",
    "\n",
    "1. [Code] Fit a logistic regression classifier to the dataset. \n",
    "\n",
    "**Hint:** Firstly create a `StandardScaler()` object called `scaler`. Then use the `scaler.fit_transform` function and pass the `X_train` dataset (or whatever you have called the features extracted from `pcb_trans_train`) and name the result `X_train_std`. Then use this normalised data for training. Next create a  `LogisticRegression` object, passing it the parameters `random_state=0` as well as`class_weight = 'balanced'.`\n",
    "\n",
    "2. [Text] Explain why we should scale the training set?\n",
    "3. [Text] Explain why we use the `class_weight = 'balanced'` argument?\n",
    "4. [Code] Report the same evaluation measures as reported for GaussianNB and Decision Trees.\n",
    "5. [Text] Comment on the measures and the confusion matrix, classification report, comparing with the other methods tried. Does it look like what you would have expected? \n",
    "6. [Code] Display the coefficients of the logistic regression in a `DataFrame` labelled with the feature names. **Hint:** The coefficients can be found in `logr._coefs` and `pcb_train.columns` has the feature names. Sort the `DataFrame` in ascending order.\n",
    "7. [Text] Identify the the positive and negative coefficients with the biggest magnitudes and state their meaning (see description of dataset). Explain why the coefficients do or do not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 Comparing Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5.1 --- [14 marks] ==========\n",
    "\n",
    "1. [Text] Explain what a ROC curve shows and the meaning of Area under the Curve (AUC).\n",
    "2. [Code] On the same set of axes, plot the ROC curves for the algorithms we have applied to the data: Gaussian Naive Bayes, Decision Trees (with no regularisation), Decision Trees with regularisation and Logistic Regression.  Make sure you label the axes appropriately. Also display the Area Under the Curve (AUC). **Hint** Look at the documentation for `plot_roc_curve`.\n",
    "3. [Text] Interpret what you see: which classifier appears to be more successful? Are there any features of the curves that look strange?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5.2 --- [15 marks] ==========\n",
    "\n",
    "1. [Code] On the same set of axes, plot the precision-recall curves for the algorithms we have applied to the data: Gaussian Naive Bayes, Decision Trees (with no regularisation), Decision Trees with regularisation and Logistic Regression.  Make sure you label the axes appropriately. **Hint** Look at the documentation for `plot_precision_recall_curve`.\n",
    "2. [Text] Interpret what you see: which classifier appears to be more successful? Are there any features of the curves that look strange?\n",
    "3. [Text] Compare what information the precision-recall curve is conveying, compared with the information conveyed by the ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5.3 --- [20 marks] ==========\n",
    "\n",
    "[Text] Comment on the performance of the classifiers we have used. Why might one be working better than another? Are there any things that should have been tried? If you were going to try construct a better classifier, what would you do? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this task is to predict house prices in King County, Washington State, USA using  inear Regression. The dataset consists of [historic data of houses sold between May 2014 and May 2015](https://www.kaggle.com/harlfoxem/housesalesprediction/data).\n",
    "\n",
    "**Attribute description**\n",
    "\n",
    "- id - Unique ID for each home sold\n",
    "- date - Date of the home sale\n",
    "- price - Price of each home sold\n",
    "- bedrooms - Number of bedrooms\n",
    "- bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n",
    "- sqft_living - Square footage* of the apartments interior living space\n",
    "- sqft_lot - Square footage of the land space\n",
    "- floors - Number of floors\n",
    "- waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not\n",
    "- view - An index from 0 to 4 of how good the view of the property was\n",
    "- condition - An index from 1 to 5 on the condition of the apartment,\n",
    "- grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n",
    "- sqft_above - The square footage of the interior housing space that is above ground level\n",
    "- sqft_basement - The square footage of the interior housing space that is below ground level\n",
    "- yr_built - The year the house was initially built\n",
    "- yr_renovated - The year of the houseâ€™s last renovation\n",
    "- zipcode - What zipcode (postal code) area the house is in\n",
    "- lat - Lattitude\n",
    "- long - Longitude\n",
    "- sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "- sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors \n",
    "\n",
    "\\* _\"Square Footage\" means area in square feet. 1 square metre is 10.76 square feet. There is no need to convert to the metric system!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 6.1 --- [23 marks] ==========\n",
    "\n",
    "Answer (in brief) the following two questions:\n",
    "1. [Text] What is regression and when is linear regression the right learning task?\n",
    "2. [Text] What is the main difference between a regression and classification task? \n",
    "3. [Code] Read in the `kc_house_data.csv` data and name it `USAhousing`. Use functions to describe the dataset.\n",
    "4. [Text] Comment on the type and ranges of features just displayed.\n",
    "5. [Text] Looking at their names, identify features that may be irrelevant or harmful to the fitting and explain why this is the case.\n",
    "6. [Code] Drop the variables you have identified and provide a correlation heatmap using `seaborn` and summary statistics using pair plots. Note that the full pair plot may take a long time, so you may wish to plot only the most interesting subsets of variables or produce multiple pair plots for legibility.\n",
    "7. [Text] Comment on the correlation plots and the pair plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 6.2 --- [24 marks] ==========\n",
    "\n",
    "1. [Code] Create `X` and `y` from `USAhousing` and then use `train_test_split` to create training and test set, with the testing set being 20% of the entire data. Set the `random_state` to 0 for reproducibility. \n",
    "\n",
    "**Hint:** Look at the Lab exercises for an example.\n",
    "\n",
    "2. [Code] Fit a `LinearRegression` to the training set, print the intercept and a `DataFrame` showing the coefficient of each attribute.\n",
    "3. [Text] Describe the meaning of the intercept and the coefficients. Comment on the coefficients, including their size, and what they tell us about the relationship between the features and the price. Are there any coefficients with surprising values?\n",
    "4. [Code] Print the Root Mean Squared Error (RMSE) and $R^2$.\n",
    "5. [Text] Explain the meaning and output of the RMSE and $R^2$. What do the tell us about the fit of the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) # Your code goes here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ***Your answer goes here:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) # Your code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) ***Your answer goes here:***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
